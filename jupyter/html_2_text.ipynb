{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-02T05:20:21.679345Z",
     "start_time": "2025-07-02T05:20:21.612578Z"
    }
   },
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import html\n",
    "\n",
    "class HTMLTextExtractor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def extract_with_beautifulsoup(self, html_content):\n",
    "        \"\"\"Extract text using BeautifulSoup (most popular method)\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "            # Remove script and style elements\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.decompose()\n",
    "\n",
    "            # Get text and clean it up\n",
    "            text = soup.get_text()\n",
    "\n",
    "            # Break into lines and remove leading/trailing space\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "\n",
    "            # Break multi-headlines into a line each\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "\n",
    "            # Drop blank lines\n",
    "            text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            return f\"Error with BeautifulSoup: {e}\"\n",
    "\n",
    "    def extract_with_regex(self, html_content):\n",
    "        \"\"\"Extract text using regex (basic method)\"\"\"\n",
    "        try:\n",
    "            # Remove HTML tags\n",
    "            clean = re.compile('<.*?>')\n",
    "            text = re.sub(clean, '', html_content)\n",
    "\n",
    "            # Decode HTML entities\n",
    "            text = html.unescape(text)\n",
    "\n",
    "            # Clean up whitespace\n",
    "            text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            return f\"Error with regex: {e}\"\n",
    "\n",
    "    def extract_specific_elements(self, html_content, tags=['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "        \"\"\"Extract text from specific HTML elements only\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "            texts = []\n",
    "            for tag in tags:\n",
    "                elements = soup.find_all(tag)\n",
    "                for element in elements:\n",
    "                    text = element.get_text().strip()\n",
    "                    if text:\n",
    "                        texts.append(text)\n",
    "\n",
    "            return '\\n\\n'.join(texts)\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting specific elements: {e}\"\n",
    "\n",
    "    def extract_with_metadata(self, html_content):\n",
    "        \"\"\"Extract text along with metadata\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "            # Extract title\n",
    "            title = soup.find('title')\n",
    "            title_text = title.get_text().strip() if title else \"No title\"\n",
    "\n",
    "            # Extract meta description\n",
    "            meta_desc = soup.find('meta', attrs={'name': 'description'})\n",
    "            description = meta_desc.get('content', '') if meta_desc else ''\n",
    "\n",
    "            # Extract headings\n",
    "            headings = []\n",
    "            for i in range(1, 7):\n",
    "                h_tags = soup.find_all(f'h{i}')\n",
    "                for h in h_tags:\n",
    "                    headings.append(f\"H{i}: {h.get_text().strip()}\")\n",
    "\n",
    "            # Extract paragraphs\n",
    "            paragraphs = []\n",
    "            p_tags = soup.find_all('p')\n",
    "            for p in p_tags:\n",
    "                text = p.get_text().strip()\n",
    "                if text and len(text) > 20:  # Filter out very short paragraphs\n",
    "                    paragraphs.append(text)\n",
    "\n",
    "            # Combine everything\n",
    "            result = {\n",
    "                'title': title_text,\n",
    "                'description': description,\n",
    "                'headings': headings,\n",
    "                'paragraphs': paragraphs,\n",
    "                'full_text': self.extract_with_beautifulsoup(html_content)\n",
    "            }\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting with metadata: {e}\"\n",
    "\n",
    "    def extract_main_content(self, html_content):\n",
    "        \"\"\"Try to extract main content by removing navigation, ads, etc.\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "            # Remove unwanted elements\n",
    "            unwanted_tags = ['nav', 'footer', 'header', 'aside', 'script', 'style', 'noscript']\n",
    "            for tag in unwanted_tags:\n",
    "                for element in soup.find_all(tag):\n",
    "                    element.decompose()\n",
    "\n",
    "            # Remove elements with common ad/navigation class names\n",
    "            unwanted_classes = ['nav', 'navigation', 'menu', 'sidebar', 'ad', 'advertisement',\n",
    "                              'footer', 'header', 'social', 'share', 'comment']\n",
    "\n",
    "            for class_name in unwanted_classes:\n",
    "                for element in soup.find_all(class_=re.compile(class_name, re.I)):\n",
    "                    element.decompose()\n",
    "\n",
    "            # Look for main content areas\n",
    "            main_content = soup.find(['main', 'article']) or soup.find('div', class_=re.compile('content|main|article', re.I))\n",
    "\n",
    "            if main_content:\n",
    "                text = main_content.get_text()\n",
    "            else:\n",
    "                text = soup.get_text()\n",
    "\n",
    "            # Clean up text\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting main content: {e}\"\n",
    "\n",
    "# Example usage and testing\n",
    "def test_extractor():\n",
    "    # Sample HTML content\n",
    "    sample_html = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Sample Page Title</title>\n",
    "        <meta name=\"description\" content=\"This is a sample page description\">\n",
    "        <style>body { font-family: Arial; }</style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <nav>Navigation menu</nav>\n",
    "        <header>\n",
    "            <h1>Main Title</h1>\n",
    "        </header>\n",
    "        <main>\n",
    "            <article>\n",
    "                <h2>Article Heading</h2>\n",
    "                <p>This is the first paragraph of the article. It contains some meaningful content.</p>\n",
    "                <p>This is the second paragraph with more information about the topic.</p>\n",
    "                <h3>Subheading</h3>\n",
    "                <p>Another paragraph under the subheading with additional details.</p>\n",
    "            </article>\n",
    "        </main>\n",
    "        <aside class=\"sidebar\">Sidebar content</aside>\n",
    "        <footer>Footer information</footer>\n",
    "        <script>console.log('Some JavaScript');</script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    extractor = HTMLTextExtractor()\n",
    "\n",
    "    print(\"1. Basic text extraction with BeautifulSoup:\")\n",
    "    print(\"-\" * 50)\n",
    "    basic_text = extractor.extract_with_beautifulsoup(sample_html)\n",
    "    print(basic_text)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"2. Text extraction with regex:\")\n",
    "    print(\"-\" * 50)\n",
    "    regex_text = extractor.extract_with_regex(sample_html)\n",
    "    print(regex_text)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"3. Specific elements extraction:\")\n",
    "    print(\"-\" * 50)\n",
    "    specific_text = extractor.extract_specific_elements(sample_html)\n",
    "    print(specific_text)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"4. Main content extraction:\")\n",
    "    print(\"-\" * 50)\n",
    "    main_text = extractor.extract_main_content(sample_html)\n",
    "    print(main_text)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"5. Extraction with metadata:\")\n",
    "    print(\"-\" * 50)\n",
    "    metadata = extractor.extract_with_metadata(sample_html)\n",
    "    if isinstance(metadata, dict):\n",
    "        print(f\"Title: {metadata['title']}\")\n",
    "        print(f\"Description: {metadata['description']}\")\n",
    "        print(f\"Headings: {metadata['headings']}\")\n",
    "        print(f\"Number of paragraphs: {len(metadata['paragraphs'])}\")\n",
    "    else:\n",
    "        print(metadata)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_extractor()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Basic text extraction with BeautifulSoup:\n",
      "--------------------------------------------------\n",
      "Sample Page Title\n",
      "Navigation menu\n",
      "Main Title\n",
      "Article Heading\n",
      "This is the first paragraph of the article. It contains some meaningful content.\n",
      "This is the second paragraph with more information about the topic.\n",
      "Subheading\n",
      "Another paragraph under the subheading with additional details.\n",
      "Sidebar content\n",
      "Footer information\n",
      "\n",
      "\n",
      "2. Text extraction with regex:\n",
      "--------------------------------------------------\n",
      "Sample Page Title body { font-family: Arial; } Navigation menu Main Title Article Heading This is the first paragraph of the article. It contains some meaningful content. This is the second paragraph with more information about the topic. Subheading Another paragraph under the subheading with additional details. Sidebar content Footer information console.log('Some JavaScript');\n",
      "\n",
      "\n",
      "3. Specific elements extraction:\n",
      "--------------------------------------------------\n",
      "This is the first paragraph of the article. It contains some meaningful content.\n",
      "\n",
      "This is the second paragraph with more information about the topic.\n",
      "\n",
      "Another paragraph under the subheading with additional details.\n",
      "\n",
      "Main Title\n",
      "\n",
      "Article Heading\n",
      "\n",
      "Subheading\n",
      "\n",
      "\n",
      "4. Main content extraction:\n",
      "--------------------------------------------------\n",
      "Article Heading\n",
      "This is the first paragraph of the article. It contains some meaningful content.\n",
      "This is the second paragraph with more information about the topic.\n",
      "Subheading\n",
      "Another paragraph under the subheading with additional details.\n",
      "\n",
      "\n",
      "5. Extraction with metadata:\n",
      "--------------------------------------------------\n",
      "Title: Sample Page Title\n",
      "Description: This is a sample page description\n",
      "Headings: ['H1: Main Title', 'H2: Article Heading', 'H3: Subheading']\n",
      "Number of paragraphs: 3\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
