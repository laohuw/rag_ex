{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-21T15:05:55.402027569Z",
     "start_time": "2025-06-21T15:05:48.025429348Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_cpp import llama, Llama\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_path=\"/home/hd/py_ex/models/llama-2-7b-chat.Q4_K_M.gguf\"\n",
    "CONTEXT_SIZE=512\n",
    "ngl=20\n",
    "\n",
    "llama2 = LlamaCpp(\n",
    "        model_path=model_path,\n",
    "        temperature=0.7,\n",
    "        max_tokens=2000,\n",
    "        n_ctx=4096,\n",
    "        verbose=False\n",
    "    )\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "    )\n",
    "documents = []\n",
    "for file in os.listdir(\"../docs\"):\n",
    "  if file.endswith(\".txt\"):\n",
    "    loader = TextLoader(os.path.join(\"../docs\", file))\n",
    "    documents.extend(loader.load())\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "db=FAISS.from_documents(chunks, embedding_model)\n",
    "retriever=db.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-21T15:08:57.008159372Z",
     "start_time": "2025-06-21T15:08:56.827925372Z"
    }
   },
   "id": "47c348c20cbcb57c"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "qa_chain=RetrievalQA.from_chain_type(\n",
    "    llm=llama2,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    # chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-21T15:13:20.799118999Z",
     "start_time": "2025-06-21T15:13:20.757152410Z"
    }
   },
   "id": "7870a608d5970257"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m query=\u001B[33m\"\u001B[39m\u001B[33mWhat is RAG and how does it work?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m(qa_chain \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     result=\u001B[43mqa_chain\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mquery\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mAnswer\u001B[39m\u001B[33m\"\u001B[39m, result[\u001B[33m\"\u001B[39m\u001B[33mresult\u001B[39m\u001B[33m\"\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain/chains/base.py:167\u001B[39m, in \u001B[36mChain.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    165\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    166\u001B[39m     run_manager.on_chain_error(e)\n\u001B[32m--> \u001B[39m\u001B[32m167\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    168\u001B[39m run_manager.on_chain_end(outputs)\n\u001B[32m    170\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain/chains/base.py:157\u001B[39m, in \u001B[36mChain.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    154\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    155\u001B[39m     \u001B[38;5;28mself\u001B[39m._validate_inputs(inputs)\n\u001B[32m    156\u001B[39m     outputs = (\n\u001B[32m--> \u001B[39m\u001B[32m157\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    158\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[32m    159\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call(inputs)\n\u001B[32m    160\u001B[39m     )\n\u001B[32m    162\u001B[39m     final_outputs: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any] = \u001B[38;5;28mself\u001B[39m.prep_outputs(\n\u001B[32m    163\u001B[39m         inputs, outputs, return_only_outputs\n\u001B[32m    164\u001B[39m     )\n\u001B[32m    165\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain/chains/retrieval_qa/base.py:151\u001B[39m, in \u001B[36mBaseRetrievalQA._call\u001B[39m\u001B[34m(self, inputs, run_manager)\u001B[39m\n\u001B[32m    147\u001B[39m accepts_run_manager = (\n\u001B[32m    148\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._get_docs).parameters\n\u001B[32m    149\u001B[39m )\n\u001B[32m    150\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m accepts_run_manager:\n\u001B[32m--> \u001B[39m\u001B[32m151\u001B[39m     docs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_docs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_run_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    153\u001B[39m     docs = \u001B[38;5;28mself\u001B[39m._get_docs(question)  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain/chains/retrieval_qa/base.py:271\u001B[39m, in \u001B[36mRetrievalQA._get_docs\u001B[39m\u001B[34m(self, question, run_manager)\u001B[39m\n\u001B[32m    264\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_get_docs\u001B[39m(\n\u001B[32m    265\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    266\u001B[39m     question: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m    267\u001B[39m     *,\n\u001B[32m    268\u001B[39m     run_manager: CallbackManagerForChainRun,\n\u001B[32m    269\u001B[39m ) -> \u001B[38;5;28mlist\u001B[39m[Document]:\n\u001B[32m    270\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Get docs.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m271\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mretriever\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    272\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\n\u001B[32m    273\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain_core/retrievers.py:259\u001B[39m, in \u001B[36mBaseRetriever.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    257\u001B[39m _kwargs = kwargs \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._expects_other_args \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[32m    258\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._new_arg_supported:\n\u001B[32m--> \u001B[39m\u001B[32m259\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_relevant_documents\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    260\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m_kwargs\u001B[49m\n\u001B[32m    261\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    262\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    263\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._get_relevant_documents(\u001B[38;5;28minput\u001B[39m, **_kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain_core/vectorstores/base.py:1079\u001B[39m, in \u001B[36mVectorStoreRetriever._get_relevant_documents\u001B[39m\u001B[34m(self, query, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1077\u001B[39m _kwargs = \u001B[38;5;28mself\u001B[39m.search_kwargs | kwargs\n\u001B[32m   1078\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.search_type == \u001B[33m\"\u001B[39m\u001B[33msimilarity\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1079\u001B[39m     docs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mvectorstore\u001B[49m\u001B[43m.\u001B[49m\u001B[43msimilarity_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1080\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.search_type == \u001B[33m\"\u001B[39m\u001B[33msimilarity_score_threshold\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1081\u001B[39m     docs_and_similarities = (\n\u001B[32m   1082\u001B[39m         \u001B[38;5;28mself\u001B[39m.vectorstore.similarity_search_with_relevance_scores(\n\u001B[32m   1083\u001B[39m             query, **_kwargs\n\u001B[32m   1084\u001B[39m         )\n\u001B[32m   1085\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/faiss.py:643\u001B[39m, in \u001B[36mFAISS.similarity_search\u001B[39m\u001B[34m(self, query, k, filter, fetch_k, **kwargs)\u001B[39m\n\u001B[32m    623\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msimilarity_search\u001B[39m(\n\u001B[32m    624\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    625\u001B[39m     query: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    629\u001B[39m     **kwargs: Any,\n\u001B[32m    630\u001B[39m ) -> List[Document]:\n\u001B[32m    631\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Return docs most similar to query.\u001B[39;00m\n\u001B[32m    632\u001B[39m \n\u001B[32m    633\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    641\u001B[39m \u001B[33;03m        List of Documents most similar to the query.\u001B[39;00m\n\u001B[32m    642\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m643\u001B[39m     docs_and_scores = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msimilarity_search_with_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    644\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetch_k\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfetch_k\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    645\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    646\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [doc \u001B[38;5;28;01mfor\u001B[39;00m doc, _ \u001B[38;5;129;01min\u001B[39;00m docs_and_scores]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/faiss.py:515\u001B[39m, in \u001B[36mFAISS.similarity_search_with_score\u001B[39m\u001B[34m(self, query, k, filter, fetch_k, **kwargs)\u001B[39m\n\u001B[32m    491\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msimilarity_search_with_score\u001B[39m(\n\u001B[32m    492\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    493\u001B[39m     query: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    497\u001B[39m     **kwargs: Any,\n\u001B[32m    498\u001B[39m ) -> List[Tuple[Document, \u001B[38;5;28mfloat\u001B[39m]]:\n\u001B[32m    499\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Return docs most similar to query.\u001B[39;00m\n\u001B[32m    500\u001B[39m \n\u001B[32m    501\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    513\u001B[39m \u001B[33;03m        L2 distance in float. Lower score represents more similarity.\u001B[39;00m\n\u001B[32m    514\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m515\u001B[39m     embedding = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_embed_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    516\u001B[39m     docs = \u001B[38;5;28mself\u001B[39m.similarity_search_with_score_by_vector(\n\u001B[32m    517\u001B[39m         embedding,\n\u001B[32m    518\u001B[39m         k,\n\u001B[32m   (...)\u001B[39m\u001B[32m    521\u001B[39m         **kwargs,\n\u001B[32m    522\u001B[39m     )\n\u001B[32m    523\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m docs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/faiss.py:266\u001B[39m, in \u001B[36mFAISS._embed_query\u001B[39m\u001B[34m(self, text)\u001B[39m\n\u001B[32m    264\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_embed_query\u001B[39m(\u001B[38;5;28mself\u001B[39m, text: \u001B[38;5;28mstr\u001B[39m) -> List[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[32m    265\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.embedding_function, Embeddings):\n\u001B[32m--> \u001B[39m\u001B[32m266\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43membedding_function\u001B[49m\u001B[43m.\u001B[49m\u001B[43membed_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    267\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    268\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.embedding_function(text)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain_huggingface/embeddings/huggingface.py:166\u001B[39m, in \u001B[36mHuggingFaceEmbeddings.embed_query\u001B[39m\u001B[34m(self, text)\u001B[39m\n\u001B[32m    153\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Compute query embeddings using a HuggingFace transformer model.\u001B[39;00m\n\u001B[32m    154\u001B[39m \n\u001B[32m    155\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    159\u001B[39m \u001B[33;03m    Embeddings for the text.\u001B[39;00m\n\u001B[32m    160\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    161\u001B[39m embed_kwargs = (\n\u001B[32m    162\u001B[39m     \u001B[38;5;28mself\u001B[39m.query_encode_kwargs\n\u001B[32m    163\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.query_encode_kwargs) > \u001B[32m0\u001B[39m\n\u001B[32m    164\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.encode_kwargs\n\u001B[32m    165\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m166\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_embed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membed_kwargs\u001B[49m\u001B[43m)\u001B[49m[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain_huggingface/embeddings/huggingface.py:121\u001B[39m, in \u001B[36mHuggingFaceEmbeddings._embed\u001B[39m\u001B[34m(self, texts, encode_kwargs)\u001B[39m\n\u001B[32m    107\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    108\u001B[39m \u001B[33;03mEmbed a text using the HuggingFace transformer model.\u001B[39;00m\n\u001B[32m    109\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    117\u001B[39m \u001B[33;03m    List of embeddings, one for each text.\u001B[39;00m\n\u001B[32m    118\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    119\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[import]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m121\u001B[39m texts = \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreplace\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.multi_process:\n\u001B[32m    123\u001B[39m     pool = \u001B[38;5;28mself\u001B[39m._client.start_multi_process_pool()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/py_ex/llama_ex/.venv/lib/python3.13/site-packages/langchain_huggingface/embeddings/huggingface.py:121\u001B[39m, in \u001B[36mHuggingFaceEmbeddings._embed.<locals>.<lambda>\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m    107\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    108\u001B[39m \u001B[33;03mEmbed a text using the HuggingFace transformer model.\u001B[39;00m\n\u001B[32m    109\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    117\u001B[39m \u001B[33;03m    List of embeddings, one for each text.\u001B[39;00m\n\u001B[32m    118\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    119\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[import]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m121\u001B[39m texts = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreplace\u001B[49m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m), texts))\n\u001B[32m    122\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.multi_process:\n\u001B[32m    123\u001B[39m     pool = \u001B[38;5;28mself\u001B[39m._client.start_multi_process_pool()\n",
      "\u001B[31mAttributeError\u001B[39m: 'set' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "\n",
    "query=\"What is RAG and how does it work?\"\n",
    "if(qa_chain is not None):\n",
    "    result=qa_chain.invoke({\"query\", query})\n",
    "    print(\"Answer\", result[\"result\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-21T15:13:27.654615711Z",
     "start_time": "2025-06-21T15:13:27.532789991Z"
    }
   },
   "id": "27d7c67fb101181d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
